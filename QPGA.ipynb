{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast QPGA Simulations\n",
    "\n",
    "We need to ensure the following for fast simulation of QPGA:\n",
    "1. We aren't building the same matrix for each layer (2 cphase and 1 bs matrix should be sufficient to define all coupling interactions in the QPGA mesh). This saves setup time.\n",
    "2. Use kronecker phase addition: tf/tf-gpu (and likely torch as well) generally likes the BLAS- and GPU-friendly linear operations over generic kronecker products. Use diag multiplication over dense matmuls when possible.\n",
    "3. Broadcast kronecker phase addition: variables can be defined for all layers as a single variable. We then use a broadcasting operation to perform kronecker phase addition for all layers at once, which is much faster than looping over the layers.\n",
    "\n",
    "We can use the above philosophy in designing the QPGA class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import sys\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Layer\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "from qpga import np_to_k_complex, QPGA\n",
    "\n",
    "K.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOON state problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "num_samples = 100 \n",
    "\n",
    "# since the batch is the same training example,\n",
    "# the gradient is unaffected if batch size is greater than 1\n",
    "# thus we can set the batch size to be 1 without affecting performance\n",
    "in_state = np.array([1]  + [0] * (2**N - 1), dtype=np.complex128)\n",
    "out_state = 1/np.sqrt(2) * np.array([1]  + [0] * (2**N - 2) + [1], dtype=np.complex128)\n",
    "\n",
    "in_data = np_to_k_complex(np.array([in_state] * num_samples))\n",
    "out_data = np_to_k_complex(np.array([out_state] * num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameWriterCallback(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predict_state = out_data[0:1]\n",
    "        self.predictions = []\n",
    "    \n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        self.predictions.append(self.model.predict(in_data[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 68s 676ms/step - loss: 5.7336e-04 - mean_squared_error: 5.7336e-04\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.9714e-04 - mean_squared_error: 2.9714e-04\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.8878e-04 - mean_squared_error: 1.8878e-04\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 1.2813e-04 - mean_squared_error: 1.2813e-04\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 9.3122e-05 - mean_squared_error: 9.3122e-05\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 7.0258e-05 - mean_squared_error: 7.0258e-05\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 5.9780e-05 - mean_squared_error: 5.9780e-05\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 5.2653e-05 - mean_squared_error: 5.2653e-05\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 4.8574e-05 - mean_squared_error: 4.8574e-05\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 4.0512e-05 - mean_squared_error: 4.0512e-05\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 4.2382e-05 - mean_squared_error: 4.2382e-05\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 3.5456e-05 - mean_squared_error: 3.5456e-05\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 3.4983e-05 - mean_squared_error: 3.4983e-05\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 3.4235e-05 - mean_squared_error: 3.4235e-05\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 3.6322e-05 - mean_squared_error: 3.6322e-05\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 3.1807e-05 - mean_squared_error: 3.1807e-05\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 3.0791e-05 - mean_squared_error: 3.0791e-05\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 2.9293e-05 - mean_squared_error: 2.9293e-05\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 3.1059e-05 - mean_squared_error: 3.1059e-05\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 2.9090e-05 - mean_squared_error: 2.9090e-05\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "model = Sequential([QPGA(N, 4*N)])\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['mse'])\n",
    "\n",
    "callback = FrameWriterCallback()\n",
    "\n",
    "history = model.fit(in_data, out_data, epochs=20, batch_size=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849644529060256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qpga import np_to_complex\n",
    "np.abs(np.dot(np_to_complex(out_data[0:1].conj())[0], np_to_complex(model.predict(in_data[0:1]))[0]))**2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
